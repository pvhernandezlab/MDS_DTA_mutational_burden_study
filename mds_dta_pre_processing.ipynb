{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ecd5bb5",
   "metadata": {},
   "source": [
    "# A PROGNOSTIC MODEL FOR MYELODYSPLASTIC SYNDROMES BASED ON DTA MUTATIONAL BURDEN: DEVELOPMENT AND VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f10e2a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# GLOBAL WARNING CONTROL\n",
    "# ------------------------------------------------------------------\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ea4ae0",
   "metadata": {},
   "source": [
    "# Basic packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd811db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import i2bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e0d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777d6dbe",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea2b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data using saved csv file (created based on SQL query)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Folder where this script lives \n",
    "HERE = Path.cwd()\n",
    "\n",
    "# Project root -> go one level up from HERE\n",
    "PROJECT_ROOT = HERE.parent\n",
    "\n",
    "\n",
    "# Get paths to the data output folders\n",
    "OUTPUT = PROJECT_ROOT / \"output\"\n",
    "FIGURES = PROJECT_ROOT / \"figures\"\n",
    "DATA = PROJECT_ROOT / \"data\"\n",
    "\n",
    "df1 = pd.read_csv(OUTPUT / \"mds_dta_all_mds_fromsql.csv\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1fd27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a94d76",
   "metadata": {},
   "source": [
    "# OR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d91073a",
   "metadata": {},
   "source": [
    "### Connecting to SQL to gather cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ee5dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install python-dotenv\n",
    "#mamba install sqlalchemy psycopg2-binary pycopg[binary] pandas #in Terminal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd0e141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy.engine.url import URL\n",
    "from sqlalchemy import create_engine, text\n",
    "import getpass\n",
    "\n",
    "# Clear any existing PG_* environment variables first\n",
    "for key in list(os.environ.keys()):\n",
    "    if key.startswith('PG_'):\n",
    "        del os.environ[key]\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(override=True)  # override=True ensures .env values take precedence\n",
    "\n",
    "# Check what was loaded (for debugging purposes)\n",
    "#print(f\"PG_USER from env: {os.getenv('PG_USER')}\")\n",
    "#print(f\"PG_HOST from env: {os.getenv('PG_HOST')}\")\n",
    "#print(f\"PG_PORT from env: {os.getenv('PG_PORT')}\")\n",
    "#print(f\"PG_DB from env: {os.getenv('PG_DB')}\")\n",
    "\n",
    "# Prompt for secure password input (already stored in Terminal in my personal .env file)\n",
    "url = URL.create(\n",
    "    drivername=\"postgresql+psycopg\",\n",
    "    username=os.getenv(\"PG_USER\"),\n",
    "    password=os.getenv(\"PG_PASSWORD\"),\n",
    "    host=os.getenv(\"PG_HOST\"),\n",
    "    port=os.getenv(\"PG_PORT\"),\n",
    "    database=os.getenv(\"PG_DB\"),)\n",
    "\n",
    "# Create the SQLAlchemy engine with SSL disabled\n",
    "engine = create_engine(url, connect_args={\"sslmode\": \"disable\"}) # SSL disabled for local connections\n",
    "\n",
    "# Connection\n",
    "with engine.connect() as c:\n",
    "    df1 = pd.read_sql(text(\"SELECT * FROM final_project.cohort_ml_v4;\"), c)\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afccd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['os_months'].describe() \n",
    "# since there is a month = 0, we will add 0.1 to all months to avoid issues with log(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab637217",
   "metadata": {},
   "source": [
    "## Columns/ variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91101f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data for ML model - patient ID and sample ID are not included\n",
    "\n",
    "dff=df1[['os_months', 'os_status', 'lfs_months', 'lfs_status', # outcomes variables\n",
    "        'sex','age','mds_type', # demographics\n",
    "        'bm_blast','pb_blast','hbg','plt','wbc','anc','monocytes', # lab values/ known prognostic variables\n",
    "        'complex_karyotype','flt3_itd','mll_ptd','tmb_nonsynonymous', # genomic variables\n",
    "        'asxl1','dnmt3a','tet2', # DTA genes presence/absence\n",
    "        'asxl1_count','dnmt3a_count','tet2_count','n_dta','n_different_dta', # DTA gene mutation counts\n",
    "        'truncating_variant','asxl1_truncating_variant', # truncating variants\n",
    "        'dnmt3a_truncating_variant','tet2_truncating_variant','n_truncating_variant', # truncating variants\n",
    "        'pathogenic_asxl1','pathogenic_dnmt3a','pathogenic_tet2', # pathogenic DTA mutations\n",
    "        'revel_avg','cadd_avg','phylop_avg']] # DTA mutation computational scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe73c1f2",
   "metadata": {},
   "source": [
    "## Fix outcomes formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba26ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pre-processing - dummies (1 means deceased/ transformed to leukemia)\n",
    "cols = ['os_status', 'lfs_status']\n",
    "\n",
    "for c in cols:\n",
    "    dff[c] =(\n",
    "        dff[c]\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .str.replace(r':.*', '', regex=True)   # drop everything from first \":\" onward\n",
    "        .pipe(pd.to_numeric, errors='coerce')  # to numbers (bad/missing becomes NaN)\n",
    "        .astype('Int64')                       # nullable integer\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2af3f1",
   "metadata": {},
   "source": [
    "## Formatting variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f0d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert continuous variables to numeric and round to 2 decimals\n",
    "\n",
    "continuous = ['age','bm_blast','pb_blast','hbg','plt','wbc','anc','monocytes',\n",
    "              'tmb_nonsynonymous',\n",
    "              'asxl1_count','dnmt3a_count','tet2_count','n_dta','n_different_dta']\n",
    "\n",
    "for col in continuous:\n",
    "    dff[col] = pd.to_numeric(dff[col], errors='coerce').round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55732396",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fill NA values in DTA-related columns with 0\n",
    "\n",
    "dta_columns = [\"asxl1\",\"dnmt3a\",\"tet2\",\"asxl1_count\",\"dnmt3a_count\",\"tet2_count\",\"n_dta\",\"n_different_dta\",\n",
    "               \"truncating_variant\",\"asxl1_truncating_variant\",\"dnmt3a_truncating_variant\",\"tet2_truncating_variant\",\"n_truncating_variant\",\n",
    "               \"pathogenic_asxl1\",\"pathogenic_dnmt3a\",\"pathogenic_tet2\"]\n",
    "\n",
    "dff[dta_columns] = dff[dta_columns].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccea3a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Treat certain columns as integers (since they were previously boolean)\n",
    "to_be_integer = ['asxl1','dnmt3a','tet2','truncating_variant','asxl1_truncating_variant','dnmt3a_truncating_variant','tet2_truncating_variant','n_truncating_variant','pathogenic_asxl1','pathogenic_dnmt3a','pathogenic_tet2']\n",
    "\n",
    "for col in to_be_integer:\n",
    "    if col in dff.columns:\n",
    "        dff[col] = dff[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cd7b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c60666b",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d438f7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Grouping based on ASXL1 status since this can be relevant for prognosis\n",
    "\n",
    "for g in [\"asxl1\", \"dnmt3a\", \"tet2\"]:\n",
    "    dff[g] = dff[g].fillna(0).astype(int)\n",
    "\n",
    "def dta_group(row):\n",
    "    a, d, t = row[\"asxl1\"], row[\"dnmt3a\"], row[\"tet2\"]\n",
    "\n",
    "    # ASXL1 only\n",
    "    if (a == 1) and (d == 0) and (t == 0):\n",
    "        return \"asxl1_only\"\n",
    "\n",
    "    # non-ASXL1 (DNMT3A and/or TET2 only, NO ASXL1)\n",
    "    if (a == 0) and ((d == 1) or (t == 1)):\n",
    "        return \"non_asxl1\"\n",
    "\n",
    "    # ASXL1 + any other DTA (mixed)\n",
    "    if (a == 1) and ((d == 1) or (t == 1)):\n",
    "        return \"asxl1_mixed\"\n",
    "    \n",
    "    # No DTA mutations\n",
    "    return \"no_dta\"\n",
    "\n",
    "dff[\"dta_group\"] = dff.apply(dta_group, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0980c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807dac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Counts for each DTA group\n",
    "\n",
    "dff[\"asxl1_only_counts\"] = np.where(dff[\"dta_group\"] == \"asxl1_only\", dff[\"asxl1_count\"], 0)\n",
    "dff[\"dta_non_asxl1_counts\"] = np.where(dff[\"dta_group\"] == \"non_asxl1\", dff[\"dnmt3a_count\"] + dff[\"tet2_count\"], 0)\n",
    "dff[\"asxl1_mixed_counts\"] = np.where(dff[\"dta_group\"] == \"asxl1_mixed\", dff[\"asxl1_count\"] + dff[\"dnmt3a_count\"] + dff[\"tet2_count\"], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb0bc57",
   "metadata": {},
   "source": [
    "## `get_dummies` function/ one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55501b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transform categorical values into dummies (those not already in dummy format)\n",
    "categorical_cols = ['sex',\n",
    "                    'mds_type',\n",
    "                    'complex_karyotype',\n",
    "                    'flt3_itd',\n",
    "                    'mll_ptd',\n",
    "                    'dta_group']\n",
    "dff = pd.get_dummies(dff, columns=categorical_cols, drop_first=True, dtype=int, dummy_na=True) # drop first to avoid multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cfd3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df.drop(columns=['patient_id', 'sample_id'])  # drop ID columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2da1af1",
   "metadata": {},
   "source": [
    "# Handling NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57f5399",
   "metadata": {},
   "outputs": [],
   "source": [
    "### % of missing values per column\n",
    "missing_percent = dff.isnull().mean() * 100\n",
    "missing_percent = missing_percent[missing_percent > 0].sort_values(ascending=False)\n",
    "missing_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893889d9",
   "metadata": {},
   "source": [
    "The decision is to exclude rows with null values in `os_status` and `lfs_status` for each outcome \\\n",
    "Non DTA cases shown as NaN have been filled with zeros \\\n",
    "Variables with > 20% missing will be excluded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00042dad",
   "metadata": {},
   "source": [
    "### Adding missingness indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794275ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop columns with more than 20% missing values\n",
    "cols_to_drop = missing_percent[missing_percent > 20].index.tolist()\n",
    "dff = dff.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04433054",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Treat infinite values as NaN\n",
    "dff.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "## Adding missingness indicators\n",
    "for col in dff.columns:\n",
    "    if dff[col].isnull().any():\n",
    "        dff[col + '_nan'] = dff[col].isnull().astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7df1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98778ed",
   "metadata": {},
   "source": [
    "# Defining outcomes\n",
    "#### Outcome 1: os_status and os_months (with censoring) \n",
    "#### Outcome 2: lfs_status and lfs_months (with censoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fe653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Number of missing values in OS and LFS columns\n",
    "a=dff['os_status'].isnull().sum()\n",
    "b=dff['lfs_status'].isnull().sum()\n",
    "print(f\"Number of missing values in os_status: {a}\")\n",
    "print(f\"Number of missing values in lfs_status: {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457a809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop rows with missing values in either os_status or lfs_status -> divide dataframes and outcomes not related to each other\n",
    "df_os = dff.dropna(subset=['os_status', 'os_months']).drop(columns=['os_status_nan','lfs_status_nan','lfs_status','lfs_months'])\n",
    "df_lfs = dff.dropna(subset=['lfs_status', 'lfs_months']).drop(columns=['lfs_status_nan', 'os_status_nan','os_status','os_months'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b22adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save dataframes as csv files\n",
    "df_os.to_csv(OUTPUT / \"mds_dta_cohort_os.csv\", index=False)\n",
    "df_lfs.to_csv(OUTPUT / \"mds_dta_cohort_lfs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062cb94d",
   "metadata": {},
   "source": [
    "# Event-per-variable (EPV) analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b97299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Number of rows (patients) in each dataframe\n",
    "len(df_os), len(df_lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63a8383",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Counts of event status in each dataframe\n",
    "a=df_os['os_status'].value_counts()\n",
    "print(a)\n",
    "b=df_lfs['lfs_status'].value_counts()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6269729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Number of columns in each dataframe\n",
    "len(df_os.columns), len(df_lfs.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99e82f9",
   "metadata": {},
   "source": [
    "# Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dec762",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90a4723",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Table 2 for Manuscript - Final Version with cleaned categorical variables, labels, and variable order\n",
    "\n",
    "#mamba install tableone #in Terminal\n",
    "import pandas as pd\n",
    "from tableone import TableOne\n",
    "from openpyxl import *\n",
    "\n",
    "#  Define categorical + continuous vars\n",
    "categorical = [\n",
    "    'sex', 'mds_type', 'complex_karyotype',\n",
    "    'flt3_itd', 'mll_ptd',\n",
    "    'asxl1', 'dnmt3a', 'tet2', 'truncating_variant']\n",
    "\n",
    "continuous = [\n",
    "    'age','bm_blast','pb_blast','hbg','plt','wbc','anc','monocytes',\n",
    "    'tmb_nonsynonymous',\n",
    "    'asxl1_count','dnmt3a_count','tet2_count',\n",
    "    'n_dta','n_different_dta',\n",
    "    'asxl1_truncating_variant','dnmt3a_truncating_variant','tet2_truncating_variant',\n",
    "    'pathogenic_asxl1','pathogenic_dnmt3a','pathogenic_tet2']\n",
    "\n",
    "# Convert continuous to numeric (coercion)\n",
    "for col in continuous:\n",
    "    df1[col] = pd.to_numeric(df1[col], errors=\"coerce\")\n",
    "\n",
    "\n",
    "#  Human-readable labels\n",
    "labels = {\n",
    "    'age': 'Age (years)',\n",
    "    'sex': 'Sex',\n",
    "    'mds_type': 'MDS subtype',\n",
    "    'complex_karyotype': 'Complex karyotype',\n",
    "    'flt3_itd': 'FLT3–ITD',\n",
    "    'mll_ptd': 'MLL–PTD',\n",
    "    'asxl1': 'ASXL1 mutated',\n",
    "    'dnmt3a': 'DNMT3A mutated',\n",
    "    'tet2': 'TET2 mutated',\n",
    "    'truncating_variant': 'Any truncating variant',\n",
    "\n",
    "    'hbg': 'Hemoglobin (g/dL)',\n",
    "    'plt': 'Platelets (×10⁹/L)',\n",
    "    'wbc': 'WBC (×10⁹/L)',\n",
    "    'anc': 'ANC (×10⁹/L)',\n",
    "    'monocytes': 'Monocytes (×10⁹/L)',\n",
    "    'bm_blast': 'Bone marrow blasts (%)',\n",
    "    'pb_blast': 'Peripheral blood blasts (%)',\n",
    "\n",
    "    'tmb_nonsynonymous': 'Nonsynonymous TMB',\n",
    "    'asxl1_count': 'ASXL1 variants (count)',\n",
    "    'dnmt3a_count': 'DNMT3A variants (count)',\n",
    "    'tet2_count': 'TET2 variants (count)',\n",
    "    'n_dta': 'Total DTA variants',\n",
    "    'n_different_dta': 'Distinct DTA genes mutated',\n",
    "\n",
    "    'asxl1_truncating_variant': 'ASXL1 truncating variant',\n",
    "    'dnmt3a_truncating_variant': 'DNMT3A truncating variant',\n",
    "    'tet2_truncating_variant': 'TET2 truncating variant',\n",
    "\n",
    "    'pathogenic_asxl1': 'ASXL1 pathogenic',\n",
    "    'pathogenic_dnmt3a': 'DNMT3A pathogenic',\n",
    "    'pathogenic_tet2': 'TET2 pathogenic'}\n",
    "\n",
    "#  Order of variables (by section)\n",
    "demographics = ['age', 'sex']\n",
    "clinical_features = ['mds_type']\n",
    "laboratory_values = ['hbg','plt','wbc','anc','monocytes','bm_blast','pb_blast']\n",
    "genomic_features = ['complex_karyotype',\n",
    "    'flt3_itd','mll_ptd',\n",
    "    'asxl1','dnmt3a','tet2','truncating_variant',\n",
    "    'tmb_nonsynonymous','asxl1_count','dnmt3a_count','tet2_count',\n",
    "    'n_dta','n_different_dta',\n",
    "    'asxl1_truncating_variant','dnmt3a_truncating_variant','tet2_truncating_variant',\n",
    "    'pathogenic_asxl1','pathogenic_dnmt3a','pathogenic_tet2']\n",
    "\n",
    "variable_order = (\n",
    "    demographics +\n",
    "    clinical_features +\n",
    "    laboratory_values +\n",
    "    genomic_features)\n",
    "\n",
    "\n",
    "#  Generate TableOne\n",
    "tableS = TableOne(\n",
    "    data=df1,\n",
    "    columns=variable_order,\n",
    "    categorical=categorical,\n",
    "    rename=labels,\n",
    "    groupby=None,\n",
    "    missing=True,\n",
    "    pval=False,\n",
    "    label_suffix=True\n",
    ")\n",
    "\n",
    "# Convert to DataFrame for editing\n",
    "df_table = tableS.tableone.copy()\n",
    "\n",
    "# MultiIndex level 0 labels\n",
    "level0 = df_table.index.get_level_values(0)\n",
    "\n",
    "#  Function to insert section header rows\n",
    "def insert_header(df, header_text, anchor_label):\n",
    "    \"\"\"Insert a bold header above the first occurrence of anchor_label.\"\"\"\n",
    "    loc = list(level0).index(anchor_label)  # find anchor row\n",
    "    header_idx = pd.MultiIndex.from_tuples([(header_text, '')])\n",
    "    header_row = pd.DataFrame({df.columns[0]: [f\"**{header_text}**\"]},\n",
    "                              index=header_idx)\n",
    "    top = df.iloc[:loc]\n",
    "    bottom = df.iloc[loc:]\n",
    "    return pd.concat([top, header_row, bottom])\n",
    "\n",
    "#  Insert section headers\n",
    "df_table = insert_header(df_table, \"Genomic features\", \"Complex karyotype, n (%)\")\n",
    "df_table = insert_header(df_table, \"Laboratory values\", \"Hemoglobin (g/dL), mean (SD)\")\n",
    "df_table = insert_header(df_table, \"Clinical features\", \"MDS subtype, n (%)\")\n",
    "df_table = insert_header(df_table, \"Demographics\", \"Age (years), mean (SD)\")\n",
    "\n",
    "\n",
    "#  Print + Export\n",
    "print(df_table)\n",
    "\n",
    "df_table.to_excel(OUTPUT / \"table_2.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36028a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mamba install tableone #in Terminal\n",
    "from tableone import TableOne\n",
    "from openpyxl import *\n",
    "\n",
    "# Categorical values for Table 1 based on df1 dataset gathered from SQL query\n",
    "categorical = ['sex','mds_type','complex_karyotype','flt3_itd','mll_ptd',\n",
    "                'asxl1','dnmt3a','tet2',\n",
    "                'truncating_variant']\n",
    "\n",
    "for col in categorical:\n",
    "    df1[col] = df1[col].replace({'None': 'Missing value', '0.0': 'No', '1.0': 'Yes'})\n",
    "    \n",
    "# Order categories for better readability\n",
    "order = {var: [\"Yes\", \"No\", \"Missing value\"] for var in categorical}\n",
    "\n",
    "# Continuous values for Table 1 based on df1 dataset gathered from SQL query\n",
    "continuous = ['age','bm_blast','pb_blast','hbg','plt','wbc','anc','monocytes',\n",
    "              'tmb_nonsynonymous',\n",
    "              'asxl1_count','dnmt3a_count','tet2_count','n_dta','n_different_dta', \n",
    "              'asxl1_truncating_variant','dnmt3a_truncating_variant','tet2_truncating_variant',\n",
    "              'pathogenic_asxl1','pathogenic_dnmt3a','pathogenic_tet2']\n",
    "\n",
    "for col in continuous:\n",
    "    df1[col] = pd.to_numeric(df1[col], errors='coerce')\n",
    "    \n",
    "# Create Table 1\n",
    "tableS = TableOne(data=df1,\n",
    "                  columns=continuous + categorical,\n",
    "                  categorical=categorical,\n",
    "                  groupby=None,\n",
    "                  order=order,\n",
    "                  pval=False,\n",
    "                  missing=True,\n",
    "                  label_suffix=True)\n",
    "\n",
    "print(tableS.tabulate(tablefmt=\"fancy_grid\"))\n",
    "\n",
    "# Save Table 1 to Excel file\n",
    "tableS.to_excel(OUTPUT/\"table_1.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bfbbdd",
   "metadata": {},
   "source": [
    "# Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbde5ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f2f5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DTA raw counts\n",
    "\n",
    "# Number of DTA versus non-DTA groups\n",
    "a = dff['dta_group_no_dta'].value_counts()\n",
    "print(f'Number of patients in DTA versus non-DTA groups: {a}')\n",
    "b = dff['dta_group_asxl1_only'].value_counts()\n",
    "print(f'Number of patients in ASXL1 DTA group: {b}')\n",
    "c= dff['dta_group_non_asxl1'].value_counts()\n",
    "print(f'Number of patients in non-ASXL1 DTA group: {c}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bab0e9",
   "metadata": {},
   "source": [
    "### Wilcoxon (Mann-Whitney) test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4251fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Wilcoxon (Mann-Whitney) test for os_months) \n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import mannwhitneyu, fisher_exact\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "TIME_COL = \"os_months\"\n",
    "EVENT_COL = \"os_status\"\n",
    "\n",
    "#  Start from main dataframe\n",
    "\n",
    "df = dff.copy()\n",
    "\n",
    "# Restrict to DTA-positive only\n",
    "df = df[df[\"n_dta\"] >= 1].copy()\n",
    "\n",
    "# Define ASXL1 vs Non-ASXL1 and DTA burden groups\n",
    "df[\"asxl1_group\"] = df[\"asxl1\"].apply(lambda x: \"ASXL1\" if x == 1.0 else \"Non-ASXL1\")\n",
    "df[\"burden_group\"] = df[\"n_dta\"].apply(lambda x: \"<2\" if x < 2 else \"≥2\")\n",
    "\n",
    "# Coerce to numeric and drop obvious missing\n",
    "df[TIME_COL]  = pd.to_numeric(df[TIME_COL], errors=\"coerce\")\n",
    "df[EVENT_COL] = pd.to_numeric(df[EVENT_COL], errors=\"coerce\")\n",
    "\n",
    "df_clean = df.dropna(subset=[TIME_COL, EVENT_COL, \"asxl1_group\", \"burden_group\"]).copy()\n",
    "\n",
    "## Wilcoxon (paired) for os_months\n",
    "#    within ASXL1 and within Non-ASXL1\n",
    "\n",
    "results_wilcoxon = []\n",
    "\n",
    "for grp in [\"ASXL1\", \"Non-ASXL1\"]:\n",
    "    sub = df_clean[df_clean[\"asxl1_group\"] == grp]\n",
    "\n",
    "    t_low  = sub[sub[\"burden_group\"] == \"<2\"][TIME_COL]\n",
    "    t_high = sub[sub[\"burden_group\"] == \"≥2\"][TIME_COL]\n",
    "\n",
    "    # Only run test if both groups have data\n",
    "    if len(t_low) > 0 and len(t_high) > 0:\n",
    "        stat, p = mannwhitneyu(t_low, t_high, alternative=\"two-sided\")\n",
    "        results_wilcoxon.append({\n",
    "            \"ASXL1_group\": grp,\n",
    "            \"n_<2\": len(t_low),\n",
    "            \"n_≥2\": len(t_high),\n",
    "            \"median_<2\": t_low.median(),\n",
    "            \"median_≥2\": t_high.median(),\n",
    "            \"MWU_statistic\": stat,\n",
    "            \"p_value\": p,\n",
    "        })\n",
    "\n",
    "wilcoxon_df = pd.DataFrame(results_wilcoxon)\n",
    "print(\"Wilcoxon (Mann-Whitney) tests for os_months (by ASXL1 stratum):\")\n",
    "print(wilcoxon_df.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de13b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Wilcoxon (Mann-Whitney) test for lfs_months) \n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import mannwhitneyu, fisher_exact\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "TIME_COL = \"lfs_months\"\n",
    "EVENT_COL = \"lfs_status\"\n",
    "\n",
    "#  Start from main dataframe\n",
    "\n",
    "df = dff.copy()\n",
    "\n",
    "# Restrict to DTA-positive only\n",
    "df = df[df[\"n_dta\"] >= 1].copy()\n",
    "\n",
    "# Define ASXL1 vs Non-ASXL1 and DTA burden groups\n",
    "df[\"asxl1_group\"] = df[\"asxl1\"].apply(lambda x: \"ASXL1\" if x == 1.0 else \"Non-ASXL1\")\n",
    "df[\"burden_group\"] = df[\"n_dta\"].apply(lambda x: \"<2\" if x < 2 else \"≥2\")\n",
    "\n",
    "# Coerce to numeric and drop obvious missing\n",
    "df[TIME_COL]  = pd.to_numeric(df[TIME_COL], errors=\"coerce\")\n",
    "df[EVENT_COL] = pd.to_numeric(df[EVENT_COL], errors=\"coerce\")\n",
    "\n",
    "df_clean = df.dropna(subset=[TIME_COL, EVENT_COL, \"asxl1_group\", \"burden_group\"]).copy()\n",
    "\n",
    "## Wilcoxon (paired) for os_months\n",
    "#    within ASXL1 and within Non-ASXL1\n",
    "\n",
    "results_wilcoxon = []\n",
    "\n",
    "for grp in [\"ASXL1\", \"Non-ASXL1\"]:\n",
    "    sub = df_clean[df_clean[\"asxl1_group\"] == grp]\n",
    "\n",
    "    t_low  = sub[sub[\"burden_group\"] == \"<2\"][TIME_COL]\n",
    "    t_high = sub[sub[\"burden_group\"] == \"≥2\"][TIME_COL]\n",
    "\n",
    "    # Only run test if both groups have data\n",
    "    if len(t_low) > 0 and len(t_high) > 0:\n",
    "        stat, p = mannwhitneyu(t_low, t_high, alternative=\"two-sided\")\n",
    "        results_wilcoxon.append({\n",
    "            \"ASXL1_group\": grp,\n",
    "            \"n_<2\": len(t_low),\n",
    "            \"n_≥2\": len(t_high),\n",
    "            \"median_<2\": t_low.median(),\n",
    "            \"median_≥2\": t_high.median(),\n",
    "            \"MWU_statistic\": stat,\n",
    "            \"p_value\": p,\n",
    "        })\n",
    "\n",
    "wilcoxon_df = pd.DataFrame(results_wilcoxon)\n",
    "print(\"Wilcoxon (Mann-Whitney) tests for lfs_months (by ASXL1 stratum):\")\n",
    "print(wilcoxon_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e5082e",
   "metadata": {},
   "source": [
    "# Plot for survival analysis (Kaplan-Meier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb65827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Log-rank KM plots within ASXL1 vs Non-ASXL1 strata (OS outcome) - DTA-mutated only\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import multivariate_logrank_test\n",
    "\n",
    "# Settings\n",
    "TIME_COL = \"os_months\"\n",
    "EVENT_COL = \"os_status\"\n",
    "\n",
    "# Copying dataframe for reusing\n",
    "df = dff.copy()\n",
    "\n",
    "# Restrict to DTA-mutated cases only\n",
    "df = df[df[\"n_dta\"] >= 1].copy()\n",
    "\n",
    "# Define ASXL1 vs Non-ASXL1 and DTA burden groups\n",
    "df[\"asxl1_group\"] = df[\"asxl1\"].apply(lambda x: \"ASXL1\" if x == 1.0 else \"Non-ASXL1\")\n",
    "df[\"burden_group\"] = df[\"n_dta\"].apply(lambda x: \"n_dta < 2\" if x < 2 else \"n_dta ≥ 2\")\n",
    "\n",
    "# Combined 4-group variable\n",
    "df[\"combo_group\"] = df[\"asxl1_group\"] + \" & \" + df[\"burden_group\"]\n",
    "\n",
    "# Coerce survival columns\n",
    "df[TIME_COL]  = pd.to_numeric(df[TIME_COL], errors=\"coerce\")\n",
    "df[EVENT_COL] = pd.to_numeric(df[EVENT_COL], errors=\"coerce\")\n",
    "\n",
    "# Keep complete cases\n",
    "d = df.dropna(subset=[TIME_COL, EVENT_COL, \"combo_group\"]).copy()\n",
    "\n",
    "#  Global log-rank test across 4 groups\n",
    "res_global = multivariate_logrank_test(\n",
    "    event_durations=d[TIME_COL],\n",
    "    groups=d[\"combo_group\"],\n",
    "    event_observed=d[EVENT_COL])\n",
    "p_global = res_global.p_value\n",
    "print(\"Global log-rank p-value (DTA-positive only, 4 groups):\", p_global)\n",
    "\n",
    "\n",
    "#  KM curves for the 4 groups\n",
    "kmf = KaplanMeierFitter()\n",
    "\n",
    "# Define group order for consistent plotting\n",
    "group_order = [\n",
    "    \"ASXL1 & n_dta < 2\",\n",
    "    \"ASXL1 & n_dta ≥ 2\",\n",
    "    \"Non-ASXL1 & n_dta < 2\",\n",
    "    \"Non-ASXL1 & n_dta ≥ 2\",]\n",
    "\n",
    "# Map internal group names -> nice legend labels\n",
    "pretty_labels = {\n",
    "    \"ASXL1 & n_dta < 2\":        \"ASXL1 count < 2\",\n",
    "    \"ASXL1 & n_dta ≥ 2\":        \"ASXL1 count ≥ 2\",\n",
    "    \"Non-ASXL1 & n_dta < 2\":    \"Non-ASXL1 count < 2\",\n",
    "    \"Non-ASXL1 & n_dta ≥ 2\":    \"Non-ASXL1 count ≥ 2\",}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "for grp in group_order:\n",
    "    sub = d[d[\"combo_group\"] == grp]\n",
    "    if sub.empty:\n",
    "        continue  # skip groups that don't exist\n",
    "    kmf.fit(\n",
    "        durations=sub[TIME_COL],\n",
    "        event_observed=sub[EVENT_COL],\n",
    "        label=grp\n",
    "    )\n",
    "    kmf.plot_survival_function(ax=ax, ci_show=True)\n",
    "\n",
    "\n",
    "# Get the existing legend handles (one per group)\n",
    "handles, _ = ax.get_legend_handles_labels()\n",
    "\n",
    "custom_labels = [\n",
    "    \"ASXL1 count < 2\",\n",
    "    \"ASXL1 count ≥ 2\",\n",
    "    \"Non-ASXL1 count < 2\",\n",
    "    \"Non-ASXL1 count ≥ 2\",\n",
    "]\n",
    "\n",
    "# Force the legend to use our labels\n",
    "ax.legend(handles[:4], custom_labels, title=\"Group\", loc=\"best\")\n",
    "\n",
    "ax.set_title(\"Overall Survival by ASXL1 Status and DTA Burden\\n(DTA-mutated only)\")\n",
    "ax.set_xlabel(\"Time (months)\")\n",
    "ax.set_ylabel(\"Survival probability\")\n",
    "\n",
    "# Remove any existing text and add new one\n",
    "for txt in list(ax.texts):\n",
    "    txt.remove()\n",
    "\n",
    "# Add global p-value on the plot\n",
    "ax.text(0.07, 0.95, f\"Global log-rank p < 0.01\",transform=ax.transAxes, ha = \"left\", va = \"top\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES / \"km_os.tiff\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4993cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stats on the plot above with pairwise comparisons - DTA-positive only (OS)\n",
    "\n",
    "import pandas as pd\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import multivariate_logrank_test, logrank_test\n",
    "from itertools import combinations\n",
    "\n",
    "# For multiple testing correction (Bonferroni/Holm/FDR)\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "#  Basic setup & DTA-only subset\n",
    "\n",
    "TIME_COL = \"os_months\"\n",
    "EVENT_COL = \"os_status\"\n",
    "\n",
    "# Start from main dataframe\n",
    "df = dff.copy()\n",
    "\n",
    "# Keep only DTA-positive cases\n",
    "df = df[df[\"n_dta\"] >= 1].copy()\n",
    "\n",
    "# Coerce time & event to numeric\n",
    "df[TIME_COL]  = pd.to_numeric(df[TIME_COL], errors=\"coerce\")\n",
    "df[EVENT_COL] = pd.to_numeric(df[EVENT_COL], errors=\"coerce\")\n",
    "\n",
    "\n",
    "##  Define groups within DTA-positive--\n",
    "# ASXL1 vs Non-ASXL1\n",
    "df[\"dta_group\"] = df[\"asxl1\"].apply(lambda x: \"ASXL1\" if x == 1.0 else \"Non-ASXL1\")\n",
    "\n",
    "# DTA burden: <2 vs ≥2 (still makes sense because n_dta >= 1 here)\n",
    "df[\"burden_group\"] = df[\"n_dta\"].apply(lambda x: \"n_dta < 2\" if x < 2 else \"n_dta ≥ 2\")\n",
    "\n",
    "# Combined 4-level group\n",
    "df[\"combo_group\"] = df[\"dta_group\"] + \" & \" + df[\"burden_group\"]\n",
    "\n",
    "# Keep complete cases\n",
    "d = df.dropna(subset=[TIME_COL, EVENT_COL, \"combo_group\"]).copy()\n",
    "\n",
    "\n",
    "# 3) Quick group summary \n",
    "summary = (\n",
    "    d.groupby(\"combo_group\")\n",
    "     .agg(\n",
    "         n      = (TIME_COL, \"size\"),\n",
    "         events = (EVENT_COL, \"sum\"),\n",
    "         median_time = (TIME_COL, \"median\")\n",
    "     )\n",
    "     .reset_index()\n",
    ")\n",
    "print(\"Group summary (DTA-positive only), OS outcome:\")\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "## Global log-rank test (4 groups, DTA-only) - OS outcome\n",
    "results_global = multivariate_logrank_test(\n",
    "    event_durations=d[TIME_COL],\n",
    "    groups=d[\"combo_group\"],\n",
    "    event_observed=d[EVENT_COL]\n",
    ")\n",
    "p_global = results_global.p_value\n",
    "print(\"\\nGlobal log-rank test p-value (DTA-positive only, 4 groups, OS outcome):\", p_global)\n",
    "\n",
    "## Pairwise log-rank tests within DTA-positive cohort - OS outcome\n",
    "group_order = [\n",
    "    \"ASXL1 & n_dta < 2\",\n",
    "    \"ASXL1 & n_dta ≥ 2\",\n",
    "    \"Non-ASXL1 & n_dta < 2\",\n",
    "    \"Non-ASXL1 & n_dta ≥ 2\",\n",
    "]\n",
    "\n",
    "pairwise_results = []\n",
    "\n",
    "for g1, g2 in combinations(group_order, 2):\n",
    "    d1 = d[d[\"combo_group\"] == g1]\n",
    "    d2 = d[d[\"combo_group\"] == g2]\n",
    "\n",
    "    # Skip if a group is empty (can happen if some combos don't exist)\n",
    "    if d1.empty or d2.empty:\n",
    "        continue\n",
    "\n",
    "    res = logrank_test(\n",
    "        d1[TIME_COL], d2[TIME_COL],\n",
    "        event_observed_A=d1[EVENT_COL],\n",
    "        event_observed_B=d2[EVENT_COL]\n",
    "    )\n",
    "\n",
    "    pairwise_results.append({\n",
    "        \"group1\": g1,\n",
    "        \"group2\": g2,\n",
    "        \"p_raw\": res.p_value,\n",
    "        \"test_statistic\": res.test_statistic,\n",
    "        \"n1\": len(d1),\n",
    "        \"n2\": len(d2),\n",
    "    })\n",
    "\n",
    "df_pairs_dta = pd.DataFrame(pairwise_results)\n",
    "\n",
    "if not df_pairs_dta.empty:\n",
    "    # Multiple testing correction (Bonferroni, Holm, FDR)\n",
    "    pvals = df_pairs_dta[\"p_raw\"].values\n",
    "\n",
    "    df_pairs_dta[\"p_bonf\"] = multipletests(pvals, method=\"bonferroni\")[1]\n",
    "    df_pairs_dta[\"p_holm\"] = multipletests(pvals, method=\"holm\")[1]\n",
    "    df_pairs_dta[\"p_fdr\"]  = multipletests(pvals, method=\"fdr_bh\")[1]\n",
    "\n",
    "    print(\"\\nPairwise log-rank tests (DTA-positive only), OS outcome:\")\n",
    "    print(df_pairs_dta.sort_values(\"p_raw\").to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNo valid pairwise comparisons (some groups may be empty), OS outcome.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18922f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Log-rank KM plots within ASXL1 vs Non-ASXL1 strata (LFS outcome) - DTA-mutated only\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import multivariate_logrank_test\n",
    "\n",
    "# Settings\n",
    "TIME_COL = \"lfs_months\"\n",
    "EVENT_COL = \"lfs_status\"\n",
    "\n",
    "# Copying dataframe for reusing\n",
    "df = dff.copy()\n",
    "\n",
    "# Restrict to DTA-mutated cases only\n",
    "df = df[df[\"n_dta\"] >= 1].copy()\n",
    "\n",
    "# Define ASXL1 vs Non-ASXL1 and DTA burden groups\n",
    "df[\"asxl1_group\"] = df[\"asxl1\"].apply(lambda x: \"ASXL1\" if x == 1.0 else \"Non-ASXL1\")\n",
    "df[\"burden_group\"] = df[\"n_dta\"].apply(lambda x: \"n_dta < 2\" if x < 2 else \"n_dta ≥ 2\")\n",
    "\n",
    "# Combined 4-group variable\n",
    "df[\"combo_group\"] = df[\"asxl1_group\"] + \" & \" + df[\"burden_group\"]\n",
    "\n",
    "# Coerce survival columns\n",
    "df[TIME_COL]  = pd.to_numeric(df[TIME_COL], errors=\"coerce\")\n",
    "df[EVENT_COL] = pd.to_numeric(df[EVENT_COL], errors=\"coerce\")\n",
    "\n",
    "# Keep complete cases\n",
    "d = df.dropna(subset=[TIME_COL, EVENT_COL, \"combo_group\"]).copy()\n",
    "\n",
    "#  Global log-rank test across 4 groups\n",
    "res_global = multivariate_logrank_test(\n",
    "    event_durations=d[TIME_COL],\n",
    "    groups=d[\"combo_group\"],\n",
    "    event_observed=d[EVENT_COL])\n",
    "p_global = res_global.p_value\n",
    "print(\"Global log-rank p-value (DTA-positive only, 4 groups), LFS outcome:\", p_global)\n",
    "\n",
    "\n",
    "#  KM curves for the 4 groups\n",
    "kmf = KaplanMeierFitter()\n",
    "\n",
    "# Define group order for consistent plotting\n",
    "group_order = [\n",
    "    \"ASXL1 & n_dta < 2\",\n",
    "    \"ASXL1 & n_dta ≥ 2\",\n",
    "    \"Non-ASXL1 & n_dta < 2\",\n",
    "    \"Non-ASXL1 & n_dta ≥ 2\",]\n",
    "\n",
    "# Map internal group names -> nice legend labels\n",
    "pretty_labels = {\n",
    "    \"ASXL1 & n_dta < 2\":        \"ASXL1 count < 2\",\n",
    "    \"ASXL1 & n_dta ≥ 2\":        \"ASXL1 count ≥ 2\",\n",
    "    \"Non-ASXL1 & n_dta < 2\":    \"Non-ASXL1 count < 2\",\n",
    "    \"Non-ASXL1 & n_dta ≥ 2\":    \"Non-ASXL1 count ≥ 2\",}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "for grp in group_order:\n",
    "    sub = d[d[\"combo_group\"] == grp]\n",
    "    if sub.empty:\n",
    "        continue  # skip groups that don't exist\n",
    "    kmf.fit(\n",
    "        durations=sub[TIME_COL],\n",
    "        event_observed=sub[EVENT_COL],\n",
    "        label=grp\n",
    "    )\n",
    "    kmf.plot_survival_function(ax=ax, ci_show=True)\n",
    "\n",
    "\n",
    "# Get the existing legend handles (one per group)\n",
    "handles, _ = ax.get_legend_handles_labels()\n",
    "\n",
    "custom_labels = [\n",
    "    \"ASXL1 count < 2\",\n",
    "    \"ASXL1 count ≥ 2\",\n",
    "    \"Non-ASXL1 count < 2\",\n",
    "    \"Non-ASXL1 count ≥ 2\",\n",
    "]\n",
    "\n",
    "# Force the legend to use our labels\n",
    "ax.legend(handles[:4], custom_labels, title=\"Group\", loc=\"best\")\n",
    "\n",
    "ax.set_title(\"Overall Leukemia-Free Survival by ASXL1 Status and DTA Burden\\n(DTA-mutated only)\")\n",
    "ax.set_xlabel(\"Time (months)\")\n",
    "ax.set_ylabel(\"Survival probability\")\n",
    "\n",
    "# Remove any existing text and add new one\n",
    "for txt in list(ax.texts):\n",
    "    txt.remove()\n",
    "\n",
    "# Add global p-value on the plot\n",
    "ax.text(0.07, 0.95, f\"Global log-rank p < 0.01\",transform=ax.transAxes, ha = \"left\", va = \"top\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES / \"km_os.tiff\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b00e232",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stats on the plot above with pairwise comparisons - DTA-positive only (LFS)\n",
    "\n",
    "import pandas as pd\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import multivariate_logrank_test, logrank_test\n",
    "from itertools import combinations\n",
    "\n",
    "# For multiple testing correction (Bonferroni/Holm/FDR)\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "#  Basic setup & DTA-only subset\n",
    "\n",
    "TIME_COL = \"lfs_months\"\n",
    "EVENT_COL = \"lfs_status\"\n",
    "\n",
    "# Start from main dataframe\n",
    "df = dff.copy()\n",
    "\n",
    "# Keep only DTA-positive cases\n",
    "df = df[df[\"n_dta\"] >= 1].copy()\n",
    "\n",
    "# Coerce time & event to numeric\n",
    "df[TIME_COL]  = pd.to_numeric(df[TIME_COL], errors=\"coerce\")\n",
    "df[EVENT_COL] = pd.to_numeric(df[EVENT_COL], errors=\"coerce\")\n",
    "\n",
    "\n",
    "##  Define groups within DTA-positive--\n",
    "# ASXL1 vs Non-ASXL1\n",
    "df[\"dta_group\"] = df[\"asxl1\"].apply(lambda x: \"ASXL1\" if x == 1.0 else \"Non-ASXL1\")\n",
    "\n",
    "# DTA burden: <2 vs ≥2 (still makes sense because n_dta >= 1 here)\n",
    "df[\"burden_group\"] = df[\"n_dta\"].apply(lambda x: \"n_dta < 2\" if x < 2 else \"n_dta ≥ 2\")\n",
    "\n",
    "# Combined 4-level group\n",
    "df[\"combo_group\"] = df[\"dta_group\"] + \" & \" + df[\"burden_group\"]\n",
    "\n",
    "# Keep complete cases\n",
    "d = df.dropna(subset=[TIME_COL, EVENT_COL, \"combo_group\"]).copy()\n",
    "\n",
    "\n",
    "# 3) Quick group summary \n",
    "summary = (\n",
    "    d.groupby(\"combo_group\")\n",
    "     .agg(\n",
    "         n      = (TIME_COL, \"size\"),\n",
    "         events = (EVENT_COL, \"sum\"),\n",
    "         median_time = (TIME_COL, \"median\")\n",
    "     )\n",
    "     .reset_index()\n",
    ")\n",
    "print(\"Group summary (DTA-positive only), LFS outcome:\")\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "## Global log-rank test (4 groups, DTA-only) - LFS outcome\n",
    "results_global = multivariate_logrank_test(\n",
    "    event_durations=d[TIME_COL],\n",
    "    groups=d[\"combo_group\"],\n",
    "    event_observed=d[EVENT_COL]\n",
    ")\n",
    "p_global = results_global.p_value\n",
    "print(\"\\nGlobal log-rank test p-value (DTA-positive only, 4 groups, LFS outcome):\", p_global)\n",
    "\n",
    "## Pairwise log-rank tests within DTA-positive cohort - OS outcome\n",
    "group_order = [\n",
    "    \"ASXL1 & n_dta < 2\",\n",
    "    \"ASXL1 & n_dta ≥ 2\",\n",
    "    \"Non-ASXL1 & n_dta < 2\",\n",
    "    \"Non-ASXL1 & n_dta ≥ 2\",\n",
    "]\n",
    "\n",
    "pairwise_results = []\n",
    "\n",
    "for g1, g2 in combinations(group_order, 2):\n",
    "    d1 = d[d[\"combo_group\"] == g1]\n",
    "    d2 = d[d[\"combo_group\"] == g2]\n",
    "\n",
    "    # Skip if a group is empty (can happen if some combos don't exist)\n",
    "    if d1.empty or d2.empty:\n",
    "        continue\n",
    "\n",
    "    res = logrank_test(\n",
    "        d1[TIME_COL], d2[TIME_COL],\n",
    "        event_observed_A=d1[EVENT_COL],\n",
    "        event_observed_B=d2[EVENT_COL]\n",
    "    )\n",
    "\n",
    "    pairwise_results.append({\n",
    "        \"group1\": g1,\n",
    "        \"group2\": g2,\n",
    "        \"p_raw\": res.p_value,\n",
    "        \"test_statistic\": res.test_statistic,\n",
    "        \"n1\": len(d1),\n",
    "        \"n2\": len(d2),\n",
    "    })\n",
    "\n",
    "df_pairs_dta = pd.DataFrame(pairwise_results)\n",
    "\n",
    "if not df_pairs_dta.empty:\n",
    "    # Multiple testing correction (Bonferroni, Holm, FDR)\n",
    "    pvals = df_pairs_dta[\"p_raw\"].values\n",
    "\n",
    "    df_pairs_dta[\"p_bonf\"] = multipletests(pvals, method=\"bonferroni\")[1]\n",
    "    df_pairs_dta[\"p_holm\"] = multipletests(pvals, method=\"holm\")[1]\n",
    "    df_pairs_dta[\"p_fdr\"]  = multipletests(pvals, method=\"fdr_bh\")[1]\n",
    "\n",
    "    print(\"\\nPairwise log-rank tests (DTA-positive only), LFS outcome:\")\n",
    "    print(df_pairs_dta.sort_values(\"p_raw\").to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNo valid pairwise comparisons (some groups may be empty), LFS outcome.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb4b3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pydev)",
   "language": "python",
   "name": "pydev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
